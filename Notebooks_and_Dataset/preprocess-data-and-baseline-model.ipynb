{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5611364,"sourceType":"datasetVersion","datasetId":3225723}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport time\nfrom datasets import load_dataset\nfrom PIL import Image\nfrom torchvision import transforms\nfrom typing import Dict, Tuple\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-15T20:43:21.515410Z","iopub.execute_input":"2024-05-15T20:43:21.516051Z","iopub.status.idle":"2024-05-15T20:43:21.523155Z","shell.execute_reply.started":"2024-05-15T20:43:21.516020Z","shell.execute_reply":"2024-05-15T20:43:21.521916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert .jsn file to .csv\nimport json\nmscoco_train2014_que = json.load(open(f'/kaggle/input/visual-question-answering/v2_Questions_Train_mscoco/v2_OpenEnded_mscoco_train2014_questions.json','r'))\nmscoco_train2014_ans = json.load(open(f'/kaggle/input/visual-question-answering/v2_Annotations_Train_mscoco/v2_mscoco_train2014_annotations.json','r'))\n\nmscoco_train2014_que_df = pd.DataFrame(mscoco_train2014_que['questions'])\nmscoco_train2014_ans_df = pd.DataFrame(mscoco_train2014_ans['annotations'])\n\nmscoco_train2014 = pd.merge(mscoco_train2014_que_df, mscoco_train2014_ans_df, on=[\"image_id\", \"question_id\"])\n\ncols = ['image_id','question_id','question','question_type','multiple_choice_answer','answers','answer_type']\nmscoco_train2014 = mscoco_train2014[cols]\n\n\n#convert image_id to image_path\ndef image_id_to_path(subset,image_id):\n    imdir='/kaggle/input/visual-question-answering/train2014/%s/COCO_%s_%012d.jpg'\n    image_path = imdir%(subset, subset, image_id)\n    return image_path\n\nsubset = 'train2014'\nimage_path = []\nfor i in (range(len(mscoco_train2014))):\n    image_path.append(image_id_to_path(subset,mscoco_train2014['image_id'][i]))\nmscoco_train2014['image_id'] = image_path\n\n\n#create a list of multiple answers of an question\nanswers_list = []\nfor i in (range(len(mscoco_train2014))):\n    ans_list = []\n    for dic in (mscoco_train2014['answers'][i]):\n        ans_list.append(dic['answer'])\n    answers_list.append(ans_list)\nmscoco_train2014['answers'] = answers_list\n\n# save dataframe to .csv\nmscoco_train2014.to_csv(\"/kaggle/working/mscoco_train2014.csv\",index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:43:21.529896Z","iopub.execute_input":"2024-05-15T20:43:21.530205Z","iopub.status.idle":"2024-05-15T20:43:52.924343Z","shell.execute_reply.started":"2024-05-15T20:43:21.530182Z","shell.execute_reply":"2024-05-15T20:43:52.923119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mscoco_train2014_que_df","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:43:52.927143Z","iopub.execute_input":"2024-05-15T20:43:52.927507Z","iopub.status.idle":"2024-05-15T20:43:52.938805Z","shell.execute_reply.started":"2024-05-15T20:43:52.927474Z","shell.execute_reply":"2024-05-15T20:43:52.937724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mscoco_train2014_ans_df","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:43:52.940012Z","iopub.execute_input":"2024-05-15T20:43:52.940351Z","iopub.status.idle":"2024-05-15T20:43:52.996867Z","shell.execute_reply.started":"2024-05-15T20:43:52.940319Z","shell.execute_reply":"2024-05-15T20:43:52.996021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mscoco_train2014","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:43:52.999503Z","iopub.execute_input":"2024-05-15T20:43:53.000053Z","iopub.status.idle":"2024-05-15T20:43:53.018251Z","shell.execute_reply.started":"2024-05-15T20:43:53.000020Z","shell.execute_reply":"2024-05-15T20:43:53.017346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mscoco_train2014.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:43:53.019840Z","iopub.execute_input":"2024-05-15T20:43:53.020163Z","iopub.status.idle":"2024-05-15T20:43:53.028196Z","shell.execute_reply.started":"2024-05-15T20:43:53.020139Z","shell.execute_reply":"2024-05-15T20:43:53.027203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image\n\n# Display the image inline\nImage(filename=mscoco_train2014['image_id'][12])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:43:53.029354Z","iopub.execute_input":"2024-05-15T20:43:53.029719Z","iopub.status.idle":"2024-05-15T20:43:53.043185Z","shell.execute_reply.started":"2024-05-15T20:43:53.029695Z","shell.execute_reply":"2024-05-15T20:43:53.042163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Group the dataset by image_id and count the number of questions per image\nimage_counts = mscoco_train2014.groupby('image_id').size().reset_index(name='count')\nimage_counts","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:43:53.044328Z","iopub.execute_input":"2024-05-15T20:43:53.044643Z","iopub.status.idle":"2024-05-15T20:43:53.312245Z","shell.execute_reply.started":"2024-05-15T20:43:53.044613Z","shell.execute_reply":"2024-05-15T20:43:53.311218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_counts.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:43:53.313488Z","iopub.execute_input":"2024-05-15T20:43:53.313761Z","iopub.status.idle":"2024-05-15T20:43:53.319288Z","shell.execute_reply.started":"2024-05-15T20:43:53.313736Z","shell.execute_reply":"2024-05-15T20:43:53.318419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sampled_image_ids = image_counts.sample(frac=0.25, random_state=42)['image_id']\nsampled_image_ids","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:43:53.320825Z","iopub.execute_input":"2024-05-15T20:43:53.321154Z","iopub.status.idle":"2024-05-15T20:43:53.339572Z","shell.execute_reply.started":"2024-05-15T20:43:53.321130Z","shell.execute_reply":"2024-05-15T20:43:53.338682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sampled_image_ids.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:43:53.344554Z","iopub.execute_input":"2024-05-15T20:43:53.345434Z","iopub.status.idle":"2024-05-15T20:43:53.351328Z","shell.execute_reply.started":"2024-05-15T20:43:53.345398Z","shell.execute_reply":"2024-05-15T20:43:53.350271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filter the dataset to keep only the rows corresponding to the sampled image_ids\ntrain_df = mscoco_train2014[mscoco_train2014['image_id'].isin(sampled_image_ids)]\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:43:53.352517Z","iopub.execute_input":"2024-05-15T20:43:53.352786Z","iopub.status.idle":"2024-05-15T20:43:53.496785Z","shell.execute_reply.started":"2024-05-15T20:43:53.352764Z","shell.execute_reply":"2024-05-15T20:43:53.495902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:43:53.498143Z","iopub.execute_input":"2024-05-15T20:43:53.498490Z","iopub.status.idle":"2024-05-15T20:43:53.505069Z","shell.execute_reply.started":"2024-05-15T20:43:53.498459Z","shell.execute_reply":"2024-05-15T20:43:53.504131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.to_csv(\"/kaggle/working/train_sampled.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:43:53.506317Z","iopub.execute_input":"2024-05-15T20:43:53.506601Z","iopub.status.idle":"2024-05-15T20:43:55.087498Z","shell.execute_reply.started":"2024-05-15T20:43:53.506577Z","shell.execute_reply":"2024-05-15T20:43:55.086250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filter rows based on the particular value of the column\nfiltered_df = train_df[train_df['answer_type'] == 'number']\n\n# Display the filtered DataFrame\nfiltered_df","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:43:55.089078Z","iopub.execute_input":"2024-05-15T20:43:55.089822Z","iopub.status.idle":"2024-05-15T20:43:55.148659Z","shell.execute_reply.started":"2024-05-15T20:43:55.089780Z","shell.execute_reply":"2024-05-15T20:43:55.147523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the distinct values from the 'answers' column\ndistinct_values = (train_df.explode('answers'))['answers'].unique()\ndistinct_values.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:43:55.150141Z","iopub.execute_input":"2024-05-15T20:43:55.150507Z","iopub.status.idle":"2024-05-15T20:43:56.041210Z","shell.execute_reply.started":"2024-05-15T20:43:55.150476Z","shell.execute_reply":"2024-05-15T20:43:56.040258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"distinct_values = train_df['multiple_choice_answer'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:43:56.043001Z","iopub.execute_input":"2024-05-15T20:43:56.043275Z","iopub.status.idle":"2024-05-15T20:43:56.074028Z","shell.execute_reply.started":"2024-05-15T20:43:56.043251Z","shell.execute_reply":"2024-05-15T20:43:56.073242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"distinct_values.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:43:56.075123Z","iopub.execute_input":"2024-05-15T20:43:56.075378Z","iopub.status.idle":"2024-05-15T20:43:56.081207Z","shell.execute_reply.started":"2024-05-15T20:43:56.075355Z","shell.execute_reply":"2024-05-15T20:43:56.080216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:43:56.082524Z","iopub.execute_input":"2024-05-15T20:43:56.082838Z","iopub.status.idle":"2024-05-15T20:43:56.184081Z","shell.execute_reply.started":"2024-05-15T20:43:56.082815Z","shell.execute_reply":"2024-05-15T20:43:56.183219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"answer = list(train_df['multiple_choice_answer'])","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:43:56.185287Z","iopub.execute_input":"2024-05-15T20:43:56.185596Z","iopub.status.idle":"2024-05-15T20:43:56.213696Z","shell.execute_reply.started":"2024-05-15T20:43:56.185570Z","shell.execute_reply":"2024-05-15T20:43:56.212657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import string\ndef find_punctuation(text):\n    punctuation_list = []\n    for t in text:\n        for i in t:\n            if i in string.punctuation:  \n                punctuation_list.append(i)\n    punctuation_list = list(set(punctuation_list))\n    return punctuation_list\n\nans_punct_list = find_punctuation(answer)\nprint(f'{len(ans_punct_list)} punctuations found in the Answer Dataset:\\n{ans_punct_list}')","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:43:56.214892Z","iopub.execute_input":"2024-05-15T20:43:56.215193Z","iopub.status.idle":"2024-05-15T20:43:56.288153Z","shell.execute_reply.started":"2024-05-15T20:43:56.215169Z","shell.execute_reply":"2024-05-15T20:43:56.287243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming 'df' is your DataFrame and 'column_name' is the name of the column you want to check\n\n# Split each value in the column into words\nwords = train_df['multiple_choice_answer'].str.split()\n\n# Filter values that are not one-word\nnot_one_word_values = train_df.loc[words.apply(len) != 1, 'multiple_choice_answer']\n\n# Print the values that are not one-word\nprint(not_one_word_values)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:43:56.289288Z","iopub.execute_input":"2024-05-15T20:43:56.289667Z","iopub.status.idle":"2024-05-15T20:43:56.463288Z","shell.execute_reply.started":"2024-05-15T20:43:56.289634Z","shell.execute_reply":"2024-05-15T20:43:56.462311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\ndef decontractions(phrase):\n    \"\"\"decontracted takes text and convert contractions into natural form.\n     ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\"\"\"\n    # specific\n    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n    phrase = re.sub(r\"won\\’t\", \"will not\", phrase)\n    phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\n    \n    phrase = re.sub(r\"he\\'s\", \"he is\", phrase)\n    phrase = re.sub(r\"she\\'s\", \"she is\", phrase)\n    phrase = re.sub(r\"it\\'s\", \"it is\", phrase)\n    \n    phrase = re.sub(r\"he\\’s\", \"he is\", phrase)\n    phrase = re.sub(r\"she\\’s\", \"she is\", phrase)\n    phrase = re.sub(r\"it\\’s\", \"it is\", phrase)\n\n    # general\n    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n\n    phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n    phrase = re.sub(r\"\\’re\", \" are\", phrase)\n    phrase = re.sub(r\"\\’d\", \" would\", phrase)\n    phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n    phrase = re.sub(r\"\\’t\", \" not\", phrase)\n    phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n    phrase = re.sub(r\"\\’m\", \" am\", phrase)\n\n    return phrase\n\n\ndef text_preprocess(text):\n    text = text.lower()\n    text = decontractions(text) # replace contractions into natural form\n    text = re.sub('[-,:]', ' ', text) # replace the character \"-\" \",\" with space\n    text = re.sub(\"(?!<=\\d)(\\.)(?!\\d)\", '', text) # remove the character \".\", except from floating numbers\n    text = re.sub('[^A-Za-z0-9. ]+', '', text) # remove all punctuation, except A-Za-z0-9 \n    text = re.sub(' +', ' ', text) # remove extra space\n    return text\n\ndef text_preprocess_ans(text):\n    text = text.lower()\n    text = decontractions(text) # replace contractions into natural form\n    text = re.sub('[-,:]', ' ', text) # replace the character \"-\" \",\" with space\n    text = re.sub(\"(?!<=\\d)(\\.)(?!\\d)\", '', text) # remove the character \".\", except from floating numbers\n    text = re.sub('[^A-Za-z0-9.! ]+', '', text) # remove all punctuation, except A-Za-z0-9 \n    text = re.sub(' +', ' ', text) # remove extra space\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:43:56.464524Z","iopub.execute_input":"2024-05-15T20:43:56.464803Z","iopub.status.idle":"2024-05-15T20:43:56.479078Z","shell.execute_reply.started":"2024-05-15T20:43:56.464778Z","shell.execute_reply":"2024-05-15T20:43:56.478191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"question_preprocessed\"] = train_df[\"question\"].map(lambda x: text_preprocess(x))\ntrain_df[\"answer_preprocessed\"] = train_df[\"multiple_choice_answer\"].map(lambda x: text_preprocess_ans(x))","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:43:56.480282Z","iopub.execute_input":"2024-05-15T20:43:56.480555Z","iopub.status.idle":"2024-05-15T20:44:04.846013Z","shell.execute_reply.started":"2024-05-15T20:43:56.480532Z","shell.execute_reply":"2024-05-15T20:44:04.845061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:44:04.847255Z","iopub.execute_input":"2024-05-15T20:44:04.847767Z","iopub.status.idle":"2024-05-15T20:44:04.867750Z","shell.execute_reply.started":"2024-05-15T20:44:04.847730Z","shell.execute_reply":"2024-05-15T20:44:04.866879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.drop(['question', 'multiple_choice_answer'], axis=1)\n\ncols = ['image_id','question_id','question_preprocessed','question_type','answer_preprocessed','answers','answer_type']\ntrain_df = train_df[cols]\n\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:44:04.869042Z","iopub.execute_input":"2024-05-15T20:44:04.869391Z","iopub.status.idle":"2024-05-15T20:44:04.947435Z","shell.execute_reply.started":"2024-05-15T20:44:04.869361Z","shell.execute_reply":"2024-05-15T20:44:04.946534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nanswer_frequency = train_df['answer_preprocessed'].value_counts()\n\n# Select the top 20 answers based on frequency\ntop_20_answers = answer_frequency.head(20)\n\n# Plot the distribution for the top 20 answers\nplt.figure(figsize=(10, 6))\ntop_20_answers.plot(kind='bar')\nplt.title('Distribution of Top 20 Answers')\nplt.xlabel('Answer')\nplt.ylabel('Frequency')\nplt.show()\nprint(top_20_answers.sum())","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:44:04.948554Z","iopub.execute_input":"2024-05-15T20:44:04.948830Z","iopub.status.idle":"2024-05-15T20:44:05.395850Z","shell.execute_reply.started":"2024-05-15T20:44:04.948806Z","shell.execute_reply":"2024-05-15T20:44:05.394799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"answer_frequency = train_df['answer_preprocessed'].value_counts()\n\n# Select the top 20 answers based on frequency\ntop_1000_answers = answer_frequency.head(1000)\ntop_1000_answers.sum()","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:44:05.397236Z","iopub.execute_input":"2024-05-15T20:44:05.397712Z","iopub.status.idle":"2024-05-15T20:44:05.427687Z","shell.execute_reply.started":"2024-05-15T20:44:05.397684Z","shell.execute_reply":"2024-05-15T20:44:05.426454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"answer_frequency = train_df['answer_preprocessed'].value_counts()\n\ntop_1000_answers = answer_frequency.head(1000).index.tolist()\n\n# Filter the dataset to include only rows where the \"answer\" column contains one of the top 1000 answers\nfinal_train_df = train_df[train_df['answer_preprocessed'].isin(top_1000_answers)]\n\nfinal_train_df\n","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:44:05.435297Z","iopub.execute_input":"2024-05-15T20:44:05.435656Z","iopub.status.idle":"2024-05-15T20:44:05.516303Z","shell.execute_reply.started":"2024-05-15T20:44:05.435617Z","shell.execute_reply":"2024-05-15T20:44:05.515194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Assuming 'df' is your DataFrame and 'multiple_choice_answer' is the name of the column\n\n# Initialize LabelEncoder\nlabel_encoder = LabelEncoder()\n\n# Fit and transform the \"multiple_choice_answer\" column\nfinal_train_df['answer_encoded'] = label_encoder.fit_transform(final_train_df['answer_preprocessed'])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:44:05.517543Z","iopub.execute_input":"2024-05-15T20:44:05.517926Z","iopub.status.idle":"2024-05-15T20:44:05.551934Z","shell.execute_reply.started":"2024-05-15T20:44:05.517892Z","shell.execute_reply":"2024-05-15T20:44:05.550895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_train_df","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:44:05.553495Z","iopub.execute_input":"2024-05-15T20:44:05.554070Z","iopub.status.idle":"2024-05-15T20:44:05.589071Z","shell.execute_reply.started":"2024-05-15T20:44:05.554034Z","shell.execute_reply":"2024-05-15T20:44:05.588038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_train_df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:44:05.590313Z","iopub.execute_input":"2024-05-15T20:44:05.590706Z","iopub.status.idle":"2024-05-15T20:44:05.614115Z","shell.execute_reply.started":"2024-05-15T20:44:05.590672Z","shell.execute_reply":"2024-05-15T20:44:05.613049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_train_df.head(20)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:44:05.615336Z","iopub.execute_input":"2024-05-15T20:44:05.616098Z","iopub.status.idle":"2024-05-15T20:44:05.646052Z","shell.execute_reply.started":"2024-05-15T20:44:05.616064Z","shell.execute_reply":"2024-05-15T20:44:05.645149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Split each value in the column into words\n# word_counts = final_train_df['answer_preprocessed'].str.split().apply(len)\n\n# # Check if all values contain only one word\n# all_one_word = (word_counts == 1).all()\n\n# # Print the result\n# if all_one_word:\n#     print(\"All values in the column are one-word.\")\n# else:\n#     print(\"Not all values in the column are one-word.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:44:05.647205Z","iopub.execute_input":"2024-05-15T20:44:05.647475Z","iopub.status.idle":"2024-05-15T20:44:05.651389Z","shell.execute_reply.started":"2024-05-15T20:44:05.647452Z","shell.execute_reply":"2024-05-15T20:44:05.650443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Assuming 'df' is your DataFrame and 'column_name' is the name of the column you want to check\n\n# # Split each value in the column into words\n# words = final_train_df['answer_preprocessed'].str.split()\n\n# # Filter values that are not one-word\n# not_one_word_values = final_train_df.loc[words.apply(len) != 1, 'answer_preprocessed']\n\n# # Print the values that are not one-word\n# print(not_one_word_values)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:44:05.652503Z","iopub.execute_input":"2024-05-15T20:44:05.653164Z","iopub.status.idle":"2024-05-15T20:44:05.660680Z","shell.execute_reply.started":"2024-05-15T20:44:05.653134Z","shell.execute_reply":"2024-05-15T20:44:05.659679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_train_df.to_csv(\"/kaggle/working/textpreprocessed_labelencoding.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:44:05.662059Z","iopub.execute_input":"2024-05-15T20:44:05.662677Z","iopub.status.idle":"2024-05-15T20:44:07.086953Z","shell.execute_reply.started":"2024-05-15T20:44:05.662653Z","shell.execute_reply":"2024-05-15T20:44:07.085899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom transformers import BertTokenizer, AutoImageProcessor\n\nclass VQADataset(Dataset):\n    def __init__(self, dataframe, bert_tokenizer, image_processor):\n        self.dataframe = dataframe\n        self.bert_tokenizer = bert_tokenizer\n        self.image_processor = image_processor\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        row = self.dataframe.iloc[idx]\n        \n        # Process the text\n        text_inputs = self.bert_tokenizer(\n            row['question_preprocessed'],\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        \n        # Process the image\n        image = Image.open(row['image_id']).convert(\"RGB\")\n        image_inputs = self.image_processor(images=image, return_tensors='pt')\n        \n        # Prepare the label\n        label = torch.tensor(row['answer_encoded'], dtype=torch.long)\n        \n        # Merge the inputs\n        inputs = {\n            'input_ids': text_inputs['input_ids'].squeeze(0),\n            'attention_mask': text_inputs['attention_mask'].squeeze(0),\n            'pixel_values': image_inputs['pixel_values'].squeeze(0),\n            'labels': label\n        }\n        return inputs\n","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:44:07.088174Z","iopub.execute_input":"2024-05-15T20:44:07.088473Z","iopub.status.idle":"2024-05-15T20:44:16.788685Z","shell.execute_reply.started":"2024-05-15T20:44:07.088448Z","shell.execute_reply":"2024-05-15T20:44:16.787900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, test_df = train_test_split(final_train_df, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:44:16.789783Z","iopub.execute_input":"2024-05-15T20:44:16.790148Z","iopub.status.idle":"2024-05-15T20:44:16.841423Z","shell.execute_reply.started":"2024-05-15T20:44:16.790122Z","shell.execute_reply":"2024-05-15T20:44:16.840309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_df), len(test_df))","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:44:16.842740Z","iopub.execute_input":"2024-05-15T20:44:16.843116Z","iopub.status.idle":"2024-05-15T20:44:16.859792Z","shell.execute_reply.started":"2024-05-15T20:44:16.843082Z","shell.execute_reply":"2024-05-15T20:44:16.858807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize tokenizers\nbert_tokenizer = BertTokenizer.from_pretrained('google-bert/bert-base-uncased')\nimage_processor = AutoImageProcessor.from_pretrained('google/vit-base-patch16-224')\n\n# Create a dataset instance\ntrain_dataset = VQADataset(train_df, bert_tokenizer, image_processor)\neval_dataset = VQADataset(test_df, bert_tokenizer, image_processor)\n\n# Create a DataLoader instance\ntrain_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\ntest_dataloader = DataLoader(eval_dataset, batch_size=2, shuffle=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:44:16.861086Z","iopub.execute_input":"2024-05-15T20:44:16.861461Z","iopub.status.idle":"2024-05-15T20:44:18.610985Z","shell.execute_reply.started":"2024-05-15T20:44:16.861429Z","shell.execute_reply":"2024-05-15T20:44:18.610083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nfrom transformers import BertModel, ViTModel\n\nclass VQAModel(nn.Module):\n    def __init__(self, bert_model_name='google-bert/bert-base-uncased', vit_model_name='google/vit-base-patch16-224', num_labels=1000, intermediate_dim=128):\n        super(VQAModel, self).__init__()\n        self.bert = BertModel.from_pretrained(bert_model_name)\n        self.vit = ViTModel.from_pretrained(vit_model_name)\n        self.fusion = nn.Sequential(\n            nn.Linear(self.bert.config.hidden_size + self.vit.config.hidden_size, intermediate_dim),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n        )\n        \n        self.classifier = nn.Linear(intermediate_dim, num_labels)\n        # self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n\n    def forward(self, input_ids, attention_mask, pixel_values, labels=None):\n        # Get BERT and ViT outputs\n        bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        vit_outputs = self.vit(pixel_values=pixel_values)\n        \n        fused_output = self.fusion(\n            torch.cat(\n                [\n                    bert_outputs.pooler_output,\n                    vit_outputs.pooler_output,\n                ],\n                dim=1\n            )\n        )\n        \n        logits = self.classifier(fused_output)\n        \n        # Element-wise dot product of BERT and ViT embeddings\n#         combined = bert_outputs.last_hidden_state[:, 0, :] * vit_outputs.pooler_output\n        \n        # Classification\n#         logits = self.classifier(combined)\n        \n        if labels is not None:\n            loss_fct = nn.CrossEntropyLoss()\n            loss = loss_fct(logits, labels)\n            return loss, logits\n        else:\n            return logits\n","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:44:18.612136Z","iopub.execute_input":"2024-05-15T20:44:18.612405Z","iopub.status.idle":"2024-05-15T20:44:18.925876Z","shell.execute_reply.started":"2024-05-15T20:44:18.612381Z","shell.execute_reply":"2024-05-15T20:44:18.924935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(eval_tuple: Tuple[np.ndarray, np.ndarray]) -> Dict[str, float]:\n    logits, labels = eval_tuple\n    preds = logits.argmax(axis=-1)\n    return {\n        \"acc\": accuracy_score(labels, preds),\n        \"f1\": f1_score(labels, preds, average='weighted'),\n        \"precision\": precision_score(labels, preds, average='weighted'),\n        \"recall\": recall_score(labels, preds, average='weighted'),\n    }","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:44:18.927070Z","iopub.execute_input":"2024-05-15T20:44:18.927356Z","iopub.status.idle":"2024-05-15T20:44:18.934133Z","shell.execute_reply.started":"2024-05-15T20:44:18.927331Z","shell.execute_reply":"2024-05-15T20:44:18.933153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\nmodel = VQAModel()\nmodel.to(device)\n\n# Define the training arguments\ntraining_args = TrainingArguments(\n    output_dir='/kaggle/working',\n    num_train_epochs=2,\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir='/kaggle/working',\n    save_steps=19378,\n    save_total_limit=2,\n    logging_steps=19378,\n    report_to=[],  # Disable logging to wandb\n)\n\n# Define the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,  # assuming you have a validation dataset\n    compute_metrics=compute_metrics,  # You can define metrics if needed\n)\n\n# Track time taken for training\nstart_time = time.time()\ntrain_result = trainer.train()\nend_time = time.time()\n\ntrain_time = end_time - start_time\nprint(f\"Training time: {train_time} seconds\")\n\n# # Save the final model\n# trainer.save_model('/kaggle/working/vqa_model')\n\n# # Save the training arguments\n# training_args.save('/kaggle/working/vqa_model/training_args.bin')\n\n# for epoch in range(training_args.num_train_epochs):\n#     print(f\"Epoch {epoch}, Loss: {compute_loss(model, train_dataset)}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:44:18.935242Z","iopub.execute_input":"2024-05-15T20:44:18.935510Z","iopub.status.idle":"2024-05-15T20:45:34.856303Z","shell.execute_reply.started":"2024-05-15T20:44:18.935487Z","shell.execute_reply":"2024-05-15T20:45:34.855025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_result = trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:45:34.857553Z","iopub.status.idle":"2024-05-15T20:45:34.857914Z","shell.execute_reply.started":"2024-05-15T20:45:34.857724Z","shell.execute_reply":"2024-05-15T20:45:34.857738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Evaluation Metrics: {eval_result}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:45:34.858922Z","iopub.status.idle":"2024-05-15T20:45:34.859262Z","shell.execute_reply.started":"2024-05-15T20:45:34.859097Z","shell.execute_reply":"2024-05-15T20:45:34.859110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Training Metrics: {train_result.metrics}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-15T20:45:34.860688Z","iopub.status.idle":"2024-05-15T20:45:34.861052Z","shell.execute_reply.started":"2024-05-15T20:45:34.860875Z","shell.execute_reply":"2024-05-15T20:45:34.860893Z"},"trusted":true},"execution_count":null,"outputs":[]}]}